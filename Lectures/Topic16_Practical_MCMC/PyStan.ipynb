{
 "metadata": {
  "name": "",
  "signature": "sha256:f1aab06576e375284a98b9e8319141710d6f16aab8ce49ae06876e44c53aad7f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(1234)\n",
      "import pystan\n",
      "import scipy.stats as stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PyStan\n",
      "----\n",
      "\n",
      "Install PyStan  with\n",
      "```\n",
      "pip install pystan\n",
      "```\n",
      "\n",
      "The nice thing about PyMC is that everything is in Python. With PyStan, however, you need to use a domain specific language based on C++ synteax to specify the model and the data, which is less flexible and more work. However, in exchange you get an extremely powerful HMC package (only does HMC) that can be used in R and Python.\n",
      "\n",
      "### Useful links\n",
      "\n",
      "- [Paper describing Stan](http://www.stat.columbia.edu/~gelman/research/unpublished/stan-resubmit-JSS1293.pdf)\n",
      "- [Stan Examples and Reference Manual](https://github.com/stan-dev/example-models/wiki)\n",
      "- [PyStan docs](http://pystan.readthedocs.org/en/latest/)\n",
      "- [PyStan GitHub page](https://github.com/stan-dev/pystan)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Examples\n",
      "----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Coin toss\n",
      "\n",
      "We'll repeat the example of determining the bias of a coin from observed coin tosses. The likelihood is binomial, and  we use a beta prior."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coin_code = \"\"\"\n",
      "data {\n",
      "    int<lower=0> n; // number of tosses\n",
      "    int<lower=0> y; // number of heads\n",
      "}\n",
      "transformed data {}\n",
      "parameters {\n",
      "    real<lower=0, upper=1> p;\n",
      "}\n",
      "transformed parameters {}\n",
      "model {\n",
      "    p ~ beta(2, 2);\n",
      "    y ~ binomial(n, p);\n",
      "}\n",
      "generated quantities {}\n",
      "\"\"\"\n",
      "\n",
      "coin_dat = {\n",
      "             'n': 100,\n",
      "             'y': 61,\n",
      "            }\n",
      "\n",
      "fit = pystan.stan(model_code=coin_code, data=coin_dat, iter=1000, chains=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Loading from a file\n",
      "\n",
      "The string in coin_code can also be in a file - say `coin_code.stan` - then we can use it like so\n",
      "\n",
      "```python\n",
      "fit = pystan.stan(file='coin_code.stan', data=coin_dat, iter=1000, chains=1)\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(fit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Inference for Stan model: anon_model_7f1947cd2d39ae427cd7b6bb6e6ffd77.\n",
        "1 chains, each with iter=1000; warmup=500; thin=1; \n",
        "post-warmup draws per chain=500, total post-warmup draws=500.\n",
        "\n",
        "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
        "p      0.61  4.2e-3   0.05   0.51   0.57   0.61   0.64    0.7  131.0   1.01\n",
        "lp__ -70.26    0.07   0.68 -72.14 -70.47  -70.0 -69.79 -69.74   95.0    1.0\n",
        "\n",
        "Samples were drawn using NUTS(diag_e) at Sat Mar 21 18:12:53 2015.\n",
        "For each parameter, n_eff is a crude measure of effective sample size,\n",
        "and Rhat is the potential scale reduction factor on split chains (at \n",
        "convergence, Rhat=1).\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coin_dict = fit.extract()\n",
      "coin_dict.keys() \n",
      "# lp_ is the log posterior"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit.plot('p');\n",
      "plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Estimating mean and standard deviation of normal distribution\n",
      "\n",
      "$$\n",
      "X \\sim \\mathcal{N}(\\mu, \\sigma^2)\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_code = \"\"\"\n",
      "data {\n",
      "    int<lower=0> n; \n",
      "    real y[n]; \n",
      "}\n",
      "transformed data {}\n",
      "parameters {\n",
      "    real<lower=0, upper=100> mu;\n",
      "    real<lower=0, upper=10> sigma;\n",
      "}\n",
      "transformed parameters {}\n",
      "model {\n",
      "    y ~ normal(mu, sigma);\n",
      "}\n",
      "generated quantities {}\n",
      "\"\"\"\n",
      "\n",
      "norm_dat = {\n",
      "             'n': 100,\n",
      "             'y': np.random.normal(10, 2, 100),\n",
      "            }\n",
      "\n",
      "fit = pystan.stan(model_code=norm_code, data=norm_dat, iter=1000, chains=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trace = fit.extract()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(10,4))\n",
      "plt.subplot(1,2,1); \n",
      "plt.hist(trace['mu'][:], 25, histtype='step');\n",
      "plt.subplot(1,2,2); \n",
      "plt.hist(trace['sigma'][:], 25, histtype='step');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Optimization (finding MAP)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sm = pystan.StanModel(model_code=norm_code)\n",
      "op = sm.optimizing(data=norm_dat)\n",
      "op"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Reusing fitted objects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_dat = {\n",
      "             'n': 100,\n",
      "             'y': np.random.normal(10, 2, 100),\n",
      "            }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit2 = pystan.stan(fit=fit, data=new_dat, chains=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fit2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Saving compiled models\n",
      "\n",
      "We can also compile Stan models and save them to file, so as to reload them for later use without needing to recompile."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save(obj, filename):\n",
      "    \"\"\"Save compiled models for reuse.\"\"\"\n",
      "    import pickle\n",
      "    with open(filename, 'w') as f:\n",
      "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
      "\n",
      "def load(filename):\n",
      "    \"\"\"Reload compiled models for reuse.\"\"\"\n",
      "    import pickle\n",
      "    return pickle.load(open(filename, 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = pystan.StanModel(model_code=norm_code)\n",
      "save(model, 'norm_model.pic')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_model = load('norm_model.pic')\n",
      "fit4 = new_model.sampling(new_dat, chains=1)\n",
      "print fit4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Estimating parameters of a linear regreession model\n",
      "\n",
      "We will show how to estimate regression parameters using a simple linear modesl\n",
      "\n",
      "$$\n",
      "y \\sim ax + b\n",
      "$$\n",
      "\n",
      "We can restate the linear model $$y = ax + b + \\epsilon$$ as sampling from a probability distribution\n",
      "\n",
      "$$\n",
      "y \\sim \\mathcal{N}(ax + b, \\sigma^2)\n",
      "$$\n",
      "\n",
      "We will assume the following priors\n",
      "\n",
      "$$\n",
      "a \\sim \\mathcal{N}(0, 100) \\\\\n",
      "b \\sim \\mathcal{N}(0, 100) \\\\\n",
      "\\sigma \\sim \\mathcal{U}(0, 20)\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lin_reg_code = \"\"\"\n",
      "data {\n",
      "    int<lower=0> n; \n",
      "    real x[n];\n",
      "    real y[n]; \n",
      "}\n",
      "transformed data {}\n",
      "parameters {\n",
      "    real a;\n",
      "    real b;\n",
      "    real sigma;\n",
      "}\n",
      "transformed parameters {\n",
      "    real mu[n];\n",
      "    for (i in 1:n) {\n",
      "        mu[i] <- a*x[i] + b;\n",
      "        }\n",
      "}\n",
      "model {\n",
      "    sigma ~ uniform(0, 20);\n",
      "    y ~ normal(mu, sigma);\n",
      "}\n",
      "generated quantities {}\n",
      "\"\"\"\n",
      "\n",
      "n = 11\n",
      "_a = 6\n",
      "_b = 2\n",
      "x = np.linspace(0, 1, n)\n",
      "y = _a*x + _b + np.random.randn(n)\n",
      "\n",
      "lin_reg_dat = {\n",
      "             'n': n,\n",
      "             'x': x,\n",
      "             'y': y\n",
      "            }\n",
      "\n",
      "fit = pystan.stan(model_code=lin_reg_code, data=lin_reg_dat, iter=1000, chains=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit.plot(['a', 'b']);\n",
      "plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Simple Logistic model\n",
      "\n",
      "We have observations of height and weight and want to use a logistic model to guess the sex."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# observed data\n",
      "df = pd.read_csv('HtWt.csv')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data {\n",
      "    int N; // number of obs (pregnancies)\n",
      "    int M; // number of groups (women)\n",
      "    int K; // number of predictors\n",
      "    \n",
      "    int y[N]; // outcome\n",
      "    row_vector[K] x[N]; // predictors\n",
      "    int g[N];    // map obs to groups (pregnancies to women)\n",
      "}\n",
      "parameters {\n",
      "    real alpha;\n",
      "    real a[M]; \n",
      "    vector[K] beta;\n",
      "    real sigma;  \n",
      "}\n",
      "model {\n",
      "  sigma ~ uniform(0, 20);\n",
      "  a ~ normal(0, sigma);\n",
      "  b ~ normal(0,sigma);\n",
      "  c ~ normal(0, sigma)\n",
      "  for(n in 1:N) {\n",
      "    y[n] ~ bernoulli(inv_logit( alpha + a[g[n]] + x[n]*beta));\n",
      "  }\n",
      "}'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_reg_code = \"\"\"\n",
      "data {\n",
      "    int<lower=0> n; \n",
      "    int male[n];\n",
      "    real weight[n];\n",
      "    real height[n];\n",
      "}\n",
      "transformed data {}\n",
      "parameters {\n",
      "    real a;\n",
      "    real b;\n",
      "    real c;\n",
      "}\n",
      "transformed parameters {}\n",
      "model {\n",
      "    a ~ normal(0, 10);\n",
      "    b ~ normal(0, 10);\n",
      "    c ~ normal(0, 10);\n",
      "    for(i in 1:n) {\n",
      "        male[i] ~ bernoulli(inv_logit(a*weight[i] + b*height[i] + c));\n",
      "  }\n",
      "}\n",
      "generated quantities {}\n",
      "\"\"\"\n",
      "\n",
      "log_reg_dat = {\n",
      "             'n': len(df),\n",
      "             'male': df.male,\n",
      "             'height': df.height,\n",
      "             'weight': df.weight\n",
      "            }\n",
      "\n",
      "fit = pystan.stan(model_code=log_reg_code, data=log_reg_dat, iter=2000, chains=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_trace = pd.DataFrame(fit.extract(['c', 'b', 'a']))\n",
      "pd.scatter_matrix(df_trace[:], diagonal='kde');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Estimating parameters of a logistic model\n",
      "\n",
      "Gelman's book has an example where the dose of a drug may be affected to the number of rat deaths in an experiment.\n",
      "\n",
      "| Dose (log g/ml) | # Rats | # Deaths |\n",
      "|-----------------|--------|----------|\n",
      "| -0.896          | 5      | 0        |\n",
      "| -0.296          | 5      | 1        |\n",
      "| -0.053          | 5      | 3        |\n",
      "| 0.727           | 5      | 5        |\n",
      "\n",
      "We will model the number of deaths as a random sample from a binomial distribution, where $n$ is the number of rats and $p$ the probabbility of a rat dying. We are given $n = 5$, but we believve that $p$ may be related to the drug dose $x$. As $x$ increases the number of rats dying seems to increase, and since $p$ is a probability, we use the following model:\n",
      "\n",
      "$$\n",
      "y \\sim \\text{Bin}(n, p) \\\\\n",
      "\\text{logit}(p) = \\alpha + \\beta x \\\\\n",
      "\\alpha \\sim \\mathcal{N}(0, 5) \\\\\n",
      "\\beta \\sim \\mathcal{N}(0, 10)\n",
      "$$\n",
      "\n",
      "where we set vague priors for $\\alpha$ and $\\beta$, the parameters for the logistic model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Original PyMC3 code\n",
      "\n",
      "```python\n",
      "n = 5 * np.ones(4)\n",
      "x = np.array([-0.896, -0.296, -0.053, 0.727])\n",
      "y = np.array([0, 1, 3, 5])\n",
      "\n",
      "def invlogit(x):\n",
      "    return pm.exp(x) / (1 + pm.exp(x))\n",
      "\n",
      "with pm.Model() as model:\n",
      "    # define priors\n",
      "    alpha = pm.Normal('alpha', mu=0, sd=5)\n",
      "    beta = pm.Flat('beta')\n",
      "    \n",
      "    # define likelihood\n",
      "    p = invlogit(alpha + beta*x)\n",
      "    y_obs = pm.Binomial('y_obs', n=n, p=p, observed=y)\n",
      "    \n",
      "    # inference\n",
      "    start = pm.find_MAP()\n",
      "    step = pm.NUTS()\n",
      "    trace = pm.sample(niter, step, start, random_seed=123, progressbar=True)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** - convert to PyStan version"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using a hierarchcical model\n",
      "\n",
      "This uses the Gelman radon data set and is based off this [IPython notebook](http://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/). Radon levels were measured in houses from all counties in several states. Here we want to know if the preence of a basement affects the level of radon, and if this is affected by which county the house is located in. \n",
      "\n",
      "The data set provided is just for the state of Minnesota, which has 85 counties with 2 to 116 measurements per county. We only need 3 columns for this example `county`, `log_radon`, `floor`, where `floor=0` indicates that there is a basement.\n",
      "\n",
      "We will perfrom simple linear regression on log_radon as a function of county and floor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "radon = pd.read_csv('radon.csv')[['county', 'floor', 'log_radon']]\n",
      "radon.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Hiearchical model\n",
      "\n",
      "With a hierarchical model, there is an $a_c$ and a $b_c$ for each county $c$ just as in the individual couty model, but they are no longer indepnedent but assumed to come from a common group distribution\n",
      "\n",
      "$$\n",
      "a_c \\sim \\mathcal{N}(\\mu_a, \\sigma_a^2) \\\\\n",
      "b_c \\sim \\mathcal{N}(\\mu_b, \\sigma_b^2)\n",
      "$$\n",
      "\n",
      "we furhter assume that the hyperparameters come from the following distributions\n",
      "\n",
      "$$\n",
      "\\mu_a \\sim \\mathcal{N}(0, 100^2) \\\\\n",
      "\\sigma_a \\sim \\mathcal{U}(0, 100) \\\\ \n",
      "\\mu_b \\sim \\mathcal{N}(0, 100^2) \\\\\n",
      "\\sigma_b \\sim \\mathcal{U}(0, 100)\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Original PyMC3 code\n",
      "\n",
      "```python\n",
      "county = pd.Categorical(radon['county']).codes\n",
      "\n",
      "with pm.Model() as hm:\n",
      "    # County hyperpriors\n",
      "    mu_a = pm.Normal('mu_a', mu=0, tau=1.0/100**2)\n",
      "    sigma_a = pm.Uniform('sigma_a', lower=0, upper=100)\n",
      "    mu_b = pm.Normal('mu_b', mu=0, tau=1.0/100**2)\n",
      "    sigma_b = pm.Uniform('sigma_b', lower=0, upper=100)\n",
      "    \n",
      "    # County slopes and intercepts\n",
      "    a = pm.Normal('slope', mu=mu_a, sd=sigma_a, shape=len(set(county)))\n",
      "    b = pm.Normal('intercept', mu=mu_b, tau=1.0/sigma_b**2, shape=len(set(county)))\n",
      "    \n",
      "    # Houseehold errors\n",
      "    sigma = pm.Gamma(\"sigma\", alpha=10, beta=1)\n",
      "    \n",
      "    # Model prediction of radon level\n",
      "    mu = a[county] + b[county] * radon.floor.values\n",
      "    \n",
      "    # Data likelihood\n",
      "    y = pm.Normal('y', mu=mu, sd=sigma, observed=radon.log_radon)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** - convert to PyStan version"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}