{
 "metadata": {
  "name": "",
<<<<<<< HEAD
  "signature": "sha256:f20074774df332ad64076916cf1e9d4e330b1411bfab89a6cf5ec634dbc87571"
=======
  "signature": "sha256:0f438ae01606772d5bfe460c1b7f0b427c412a76cc1194c1d8f6f55cd17584bf"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import string\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 68
=======
     "prompt_number": 62
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la\n",
      "import scipy.stats as st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 69
=======
     "prompt_number": 63
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 70
=======
     "prompt_number": 64
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 71
=======
     "prompt_number": 65
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Latent Semantic Analysis (LSA) is a method for reducing the dimnesionality of documents treated as a bag of words. It is used for document classification, clustering and retrieval. For example, LSA can be used to search for prior art given a new patent application. In this homework, we will implement a small library for simple latent semantic analysis as a practical example of the application of SVD. The ideas are very similar to PCA.\n",
      "\n",
      "We will implement a toy example of LSA to get familiar with the ideas. If you want to use LSA or similar methods for statiscal language analyis, the most efficient Python library is probably [gensim](https://radimrehurek.com/gensim/) - this also provides an online algorithm - i.e. the training information can be continuously updated. Other useful functions for processing natural language can be found in the [Natural Lnaguage Toolkit](http://www.nltk.org/)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note**: The SVD from scipy.linalg performs a full decomposition, which is inefficient since we only need to decompose until we get the first k singluar values. If the SVD from `scipy.linalg` is too slow, please use the `sparsesvd` function from the [sparsesvd](https://pypi.python.org/pypi/sparsesvd/) package to perform SVD instead.  You can install in the usual way with \n",
      "```\n",
      "!pip install sparsesvd\n",
      "```\n",
      "\n",
      "Then import the following\n",
      "```python\n",
      "from sparsesvd import sparsesvd \n",
      "from scipy.sparse import csc_matrix \n",
      "```\n",
      "\n",
      "and use as follows\n",
      "```python\n",
      "sparsesvd(csc_matrix(M), k=10)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 1 (10 points)**.  Calculating pairwise distance matrices.\n",
      "\n",
      "Suppose we want to construct a distance matrix between the rows of a matrix. For example, given the matrix \n",
      "\n",
      "```python\n",
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "```\n",
      "\n",
      "the distance matrix using Euclidean distance as the measure would be\n",
      "```python\n",
      "[[ 0.000  1.414  2.828]\n",
      " [ 1.414  0.000  1.414]\n",
      " [ 2.828  1.414  0.000]] \n",
      "```\n",
      "if $M$ was a collection of column vectors.\n",
      "\n",
      "Write a function to calculate the pairwise-distance matrix given the matrix $M$ and some arbitrary distance function. Your functions should have the following signature:\n",
      "```\n",
      "def func_name(M, distance_func):\n",
      "    pass\n",
      "```\n",
      "\n",
      "0. Write a distance function for the Euclidean, squared Euclidean and cosine measures.\n",
      "1. Write the function using looping for M as a collection of row vectors.\n",
      "2. Write the function using looping for M as a collection of column vectors.\n",
      "3. Wrtie the function using broadcasting for M as a colleciton of row vectors.\n",
      "4. Write the function using broadcasting for M as a colleciton of column vectors. \n",
      "\n",
      "For 3 and 4, try to avoid using transposition (but if you get stuck, there will be no penalty for using transpoition). Check that all four functions give the same result when applied to the given matrix $M$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Solution (Ex 1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = np.array([[1,2,3],[4,5,6]]).T\n",
      "Mdistrow = np.array([[ 0.000, 1.414,  2.828],\n",
      " [ 1.414,  0.000,  1.414],\n",
      " [ 2.828,  1.414,  0.000]])\n",
      "Mdistcol = np.array([[0.000, 5.196], [5.196, 0.000]])\n",
      "print M\n",
      "print Mdistrow\n",
      "print Mdistcol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1 4]\n",
        " [2 5]\n",
        " [3 6]]\n",
        "[[ 0.000  1.414  2.828]\n",
        " [ 1.414  0.000  1.414]\n",
        " [ 2.828  1.414  0.000]]\n",
        "[[ 0.000  5.196]\n",
        " [ 5.196  0.000]]\n"
       ]
      }
     ],
<<<<<<< HEAD
     "prompt_number": 72
=======
     "prompt_number": 66
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 1. Distance function for Euclidean, square Euclidean, and cosine measures\n",
      "def euclidean(x, y):\n",
      "    return np.sqrt(((x - y)**2).sum(axis=-1))\n",
      "def euclidean2(x, y):\n",
      "    return ((x - y)**2).sum(axis=-1)\n",
      "def cosine_measure(x, y):\n",
<<<<<<< HEAD
      "    return (x * v).sum(axis=-1) / (np.linalg.norm(x) * np.linalg.norm(y))"
=======
      "    lengthx = np.linalg.norm(x, ord=2) \n",
      "    lengthy = np.linalg.norm(y, ord=2)\n",
      "    return x.dot(y) / (lengthx * lengthy)"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 73
=======
     "prompt_number": 67
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 2. Write the function using looping for M as a collection of row vectors\n",
      "def loop_row(M, distance_func):\n",
      "    nrow = M.shape[0]\n",
      "    out_matrix = np.empty((nrow, nrow))\n",
      "    for i in range(nrow):\n",
      "        for j in range(nrow):\n",
      "                out_matrix[i, j] = distance_func(M[i,:], M[j,:])\n",
      "    return out_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 74
=======
     "prompt_number": 68
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3. Write the function using looping for M as a collection of column vectors\n",
      "def loop_col(M, distance_func):\n",
      "    ncol = M.shape[1]\n",
      "    out_matrix = np.empty((ncol, ncol))\n",
      "    for i in range(ncol):\n",
      "        for j in range(ncol):\n",
      "            out_matrix[i, j] = distance_func(M[:,i], M[:,j])\n",
      "    return out_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 75
=======
     "prompt_number": 69
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 4. Write the function using broadcasting for M as a collection of row vectors\n",
      "def broadcast_row(M, distance_func):\n",
      "    return distance_func(M[np.newaxis, :, :], M[:, np.newaxis, :])"
<<<<<<< HEAD
=======
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 5. Write the function using broadcasting for M as a colleciton of column vectors\n",
      "def broadcast_col(M, distance_func):\n",
      "    return distance_func(M.T[:, np.newaxis, :], M.T[np.newaxis, :, :])"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 5. Write the function using broadcasting for M as a colleciton of column vectors\n",
      "def broadcast_col(M, distance_func):\n",
      "    return distance_func(M.T[:, np.newaxis, :], M.T[np.newaxis, :, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
=======
     "prompt_number": 71
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing row functions\n",
      "np.testing.assert_array_almost_equal(loop_row(M, distance_func=euclidean), Mdistrow, decimal=3)\n",
      "np.testing.assert_array_almost_equal(broadcast_row(M, distance_func=euclidean), Mdistrow, decimal=3)\n",
      "# Testing col functions\n",
      "np.testing.assert_array_almost_equal(loop_col(M, distance_func=euclidean), Mdistcol, decimal=3)\n",
      "np.testing.assert_array_almost_equal(broadcast_col(M, distance_func=euclidean), Mdistcol, decimal=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 78
=======
     "prompt_number": 72
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 2 (10 points)**. Write 3 functions to calculate the term frequency (tf), the inverse document frequency (idf) and the product (tf-idf). Each function should take a single argument `docs`, which is a dictionary of (key=identifier, value=dcoument text) pairs, and return an appropriately sized array. Convert '-' to ' ' (space), remove punctuation, convert text to lowercase and split on whitespace to generate a collection of terms from the dcoument text.\n",
      "\n",
      "- tf = the number of occurrences of term $i$ in document $j$\n",
      "- idf = $\\log \\frac{n}{1 + \\text{df}_i}$ where $n$ is the total number of documents and $\\text{df}_i$ is the number of documents in which term $i$ occurs.\n",
      "\n",
      "Print the table of tf-idf values for the following document collection\n",
      "\n",
      "```\n",
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
      "```\n",
      "\n",
      "Note: You can use either a numpy array or pandas dataframe to store the matrix. However, we suggest using a Pnadas dataframe since that will allow you to keep track of the row (term) and column (document) names in a single object. Of course, you could also maintain a numpy matrix, a list of terms, and a list of documents separately if you prefer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 79
=======
     "prompt_number": 73
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "# Suggeste function signatures\n",
      "def tf(doc):\n",
      "    \"\"\"Returns the number of times each term occurs in a dcoument.\n",
      "    We preprocess the document to strip punctuation and convert to lowercase.\n",
      "    Terms are found by splitting on whitespace.\"\"\"\n",
      "    doc = doc.replace(\"-\", \" \").translate(None, string.punctuation).lower().split()\n",
      "    res = {}\n",
      "    for word in doc:\n",
      "        res[word] = res.get(word, 0) + 1\n",
      "    return res\n",
<<<<<<< HEAD
      "\n",
      "def tf2(doc):\n",
      "    \"\"\"Returns the number of times each term occurs in a dcoument.\n",
      "    We preprocess the document to strip punctuation and convert to lowercase.\n",
      "    Terms are found by splitting on whitespace.\"\"\"\n",
      "    from collections import Counter\n",
      "    from string import punctuation\n",
      "\n",
      "    terms = doc.lower().replace('-', ' ').translate(None, punctuation).split()\n",
      "    return Counter(terms)\n",
      "\n",
      "%timeit tf(s1)\n",
      "%timeit tf2(s1)"
=======
      "\n",
      "tf(s1)"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
<<<<<<< HEAD
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100000 loops, best of 3: 2.48 \u00b5s per loop\n",
        "100000 loops, best of 3: 11.4 \u00b5s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 206
=======
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "{'brown': 1, 'fox': 1, 'quick': 1, 'the': 1}"
       ]
      }
     ],
     "prompt_number": 74
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tfs(docs):\n",
      "    \"\"\"Create a term freqeuncy dataframe from a dictionary of documents.\"\"\"\n",
      "    return pd.DataFrame({k: tf(v) for k, v in docs.iteritems()}).fillna(0)\n",
      "\n",
      "tfs(docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>s1</th>\n",
        "      <th>s2</th>\n",
        "      <th>s3</th>\n",
        "      <th>s4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>brown</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>dog</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>elephant</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>fox</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>jumps</th>\n",
        "      <td> 0</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lazy</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lion</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>over</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>peacock</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>quick</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tiger</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
<<<<<<< HEAD
       "prompt_number": 81,
=======
       "prompt_number": 75,
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
       "text": [
        "          s1  s2  s3  s4\n",
        "brown      1   1   0   0\n",
        "dog        0   0   1   1\n",
        "elephant   0   0   1   1\n",
        "fox        1   1   0   0\n",
        "jumps      0   4   0   0\n",
        "lazy       0   0   1   0\n",
        "lion       0   0   0   1\n",
        "over       0   1   0   0\n",
        "peacock    0   0   0   1\n",
        "quick      1   0   0   0\n",
        "the        1   1   3   5\n",
        "tiger      0   0   0   1"
       ]
      }
     ],
<<<<<<< HEAD
     "prompt_number": 81
=======
     "prompt_number": 75
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def idf(docs):\n",
      "    \"\"\"Find inverse document frequecny series from a dictionry of doucmnets.\"\"\"\n",
      "    n = len(docs)\n",
      "    return np.log(float(n) / (1 + tfs(docs).sum(axis=1)))\n",
      "\n",
      "idf(docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
<<<<<<< HEAD
       "prompt_number": 82,
=======
       "prompt_number": 76,
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
       "text": [
        "brown       0.287682\n",
        "dog         0.287682\n",
        "elephant    0.287682\n",
        "fox         0.287682\n",
        "jumps      -0.223144\n",
        "lazy        0.693147\n",
        "lion        0.693147\n",
        "over        0.693147\n",
        "peacock     0.693147\n",
        "quick       0.693147\n",
        "the        -1.011601\n",
        "tiger       0.693147\n",
        "dtype: float64"
       ]
      }
     ],
<<<<<<< HEAD
     "prompt_number": 82
=======
     "prompt_number": 76
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tf_idf(docs):\n",
      "    \"\"\"Return the product of the term-frequency and inverse document freqeucny.\"\"\"\n",
      "    tfs_ = tfs(docs)\n",
      "    idf_ = idf(docs)\n",
      "    return pd.DataFrame(tfs_.values * idf_.values[:, np.newaxis], columns=tfs_.columns, index=tfs_.index)\n",
      "\n",
      "tf_idf(docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>s1</th>\n",
        "      <th>s2</th>\n",
        "      <th>s3</th>\n",
        "      <th>s4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>brown</th>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>dog</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>elephant</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>fox</th>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>jumps</th>\n",
        "      <td>-0.000000</td>\n",
        "      <td>-0.892574</td>\n",
        "      <td>-0.000000</td>\n",
        "      <td>-0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lazy</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lion</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>over</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>peacock</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>quick</th>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>-1.011601</td>\n",
        "      <td>-1.011601</td>\n",
        "      <td>-3.034803</td>\n",
        "      <td>-5.058005</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tiger</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
<<<<<<< HEAD
       "prompt_number": 83,
=======
       "prompt_number": 77,
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
       "text": [
        "                s1        s2        s3        s4\n",
        "brown     0.287682  0.287682  0.000000  0.000000\n",
        "dog       0.000000  0.000000  0.287682  0.287682\n",
        "elephant  0.000000  0.000000  0.287682  0.287682\n",
        "fox       0.287682  0.287682  0.000000  0.000000\n",
        "jumps    -0.000000 -0.892574 -0.000000 -0.000000\n",
        "lazy      0.000000  0.000000  0.693147  0.000000\n",
        "lion      0.000000  0.000000  0.000000  0.693147\n",
        "over      0.000000  0.693147  0.000000  0.000000\n",
        "peacock   0.000000  0.000000  0.000000  0.693147\n",
        "quick     0.693147  0.000000  0.000000  0.000000\n",
        "the      -1.011601 -1.011601 -3.034803 -5.058005\n",
        "tiger     0.000000  0.000000  0.000000  0.693147"
       ]
      }
     ],
<<<<<<< HEAD
     "prompt_number": 83
=======
     "prompt_number": 77
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 3 (10 points)**. \n",
      "\n",
      "1. Write a function that takes a matrix $M$ and an integer $k$ as arguments, and reconstructs a reduced matrix using only the $k$ largest singular values. Use the `scipy.linagl.svd` function to perform the decomposition. This is the least squares approximation to the matrix $M$ in $k$ dimensions.\n",
      "\n",
      "2. Apply the function you just wrote to the following term-frequency matrix for a set of $9$ documents using $k=2$ and print the reconstructed matrix $M'$.\n",
      "```\n",
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
      "```\n",
      "\n",
      "3. Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using $k=2$ singular values (you may use [scipy.stats.spearmanr](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to do the calculations). Consider the fist 5 sets of documents as one group $G1$ and the last 4 as another group $G2$ (i.e. first 5 and last 4 columns). What is the average within group correlation for $G1$, $G2$ and the average cross-group correlation for G1-G2 using either $M$ or $M'$. (Do not include self-correlation in the within-group calculations.)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 1]])"
<<<<<<< HEAD
=======
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "def reconstruct(M, k):\n",
      "    u, s, v = scipy.linalg.svd(M)\n",
      "    return u[:, :k].dot(np.diag(s[:k])).dot(v[:k, :])\n",
      "\n",
      "M_prime = reconstruct(M, k=2)"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "def reconstruct(M, k):\n",
      "    u, s, v = scipy.linalg.svd(M)\n",
      "    return u[:, :k].dot(np.diag(s[:k])).dot(v[:k, :])\n",
      "\n",
      "M_prime = reconstruct(M, k=2)\n",
      "print M_prime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.162  0.400  0.379  0.468  0.176 -0.053 -0.115 -0.159 -0.092]\n",
        " [ 0.141  0.370  0.329  0.400  0.165 -0.033 -0.071 -0.097 -0.043]\n",
        " [ 0.152  0.505  0.358  0.410  0.236  0.024  0.060  0.087  0.124]\n",
        " [ 0.258  0.841  0.606  0.697  0.392  0.033  0.083  0.122  0.187]\n",
        " [ 0.449  1.234  1.051  1.266  0.556 -0.074 -0.155 -0.210 -0.049]\n",
        " [ 0.160  0.582  0.375  0.417  0.277  0.056  0.132  0.189  0.217]\n",
        " [ 0.160  0.582  0.375  0.417  0.277  0.056  0.132  0.189  0.217]\n",
        " [ 0.218  0.550  0.511  0.628  0.243 -0.065 -0.143 -0.197 -0.108]\n",
        " [ 0.097  0.532  0.230  0.212  0.267  0.137  0.315  0.444  0.425]\n",
        " [-0.061  0.232 -0.139 -0.266  0.145  0.240  0.546  0.767  0.664]\n",
        " [-0.065  0.335 -0.146 -0.301  0.203  0.306  0.695  0.977  0.849]\n",
        " [-0.043  0.254 -0.097 -0.208  0.152  0.221  0.503  0.707  0.616]]\n"
       ]
      }
     ],
     "prompt_number": 85
=======
     "prompt_number": 83
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using k=2 singular values \n",
      "# (you may use scipy.stats.spearmanr to do the calculations). \n",
<<<<<<< HEAD
      "m_corr = scipy.stats.spearmanr(M_prime)[0]\n",
      "print m_corr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.000  0.846  1.000  0.998  0.719 -0.837 -0.837 -0.837 -0.802]\n",
        " [ 0.846  1.000  0.846  0.844  0.972 -0.557 -0.557 -0.557 -0.480]\n",
        " [ 1.000  0.846  1.000  0.998  0.719 -0.837 -0.837 -0.837 -0.802]\n",
        " [ 0.998  0.844  0.998  1.000  0.718 -0.839 -0.839 -0.839 -0.804]\n",
        " [ 0.719  0.972  0.719  0.718  1.000 -0.389 -0.389 -0.389 -0.298]\n",
        " [-0.837 -0.557 -0.837 -0.839 -0.389  1.000  1.000  1.000  0.979]\n",
        " [-0.837 -0.557 -0.837 -0.839 -0.389  1.000  1.000  1.000  0.979]\n",
        " [-0.837 -0.557 -0.837 -0.839 -0.389  1.000  1.000  1.000  0.979]\n",
        " [-0.802 -0.480 -0.802 -0.804 -0.298  0.979  0.979  0.979  1.000]]\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
=======
      "m_corr = scipy.stats.spearmanr(M)[0]\n",
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
      "# Consider the fist 5 sets of documents as one group G1 and the last 4 as another group G2 (i.e. first 5 and last 4 columns).\n",
      "# What is the average within group correlation for G1, G2 and the average cross-group correlation for G1-G2 using either M or M\u2032. \n",
      "# (Do not include self-correlation in the within-group calculations.).\n",
      "print \"G1 within group correlation: \", m_corr[:5, :5][np.triu_indices(5, k=1)].mean()\n",
      "print \"G2 within group correlation: \", m_corr[5:, 5:][np.triu_indices(4, k=1)].mean()\n",
      "print \"G1-G2 cross group correlation: \", m_corr[:5, 5:].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
<<<<<<< HEAD
        "G1 within group correlation:  0.866042884512\n",
        "G2 within group correlation:  0.98951048951\n",
        "G1-G2 cross group correlation:  -0.678168764439\n"
       ]
      }
     ],
     "prompt_number": 87
=======
        "G1 within group correlation:  0.0105776866299\n",
        "G2 within group correlation:  0.43511771482\n",
        "G1-G2 cross group correlation:  -0.307562188906\n"
       ]
      }
     ],
     "prompt_number": 101
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 4 (20 points)**. Clustering with LSA\n",
      "\n",
      "1. Begin by loading a pubmed database of selected article titles using 'cPickle'. With the following:\n",
      "```import cPickle\n",
      "docs = cPickle.load(open('pubmed.pic'))```\n",
      "\n",
      "    Create a tf-idf matrix for every term that appears at least once in any of the documents. What is the shape of the tf-idf matrix? \n",
      "\n",
      "2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$ (often written as $T \\Sigma D^T$ in this context with $T$ representing the terms and $D$ representing the documents). If we set all but the top $k$ singular values to 0, the reconstructed matrix is essentially $U_k \\Sigma_k V_k^T$, where $U_k$ is $m \\times k$, $\\Sigma_k$ is $k \\times k$ and $V_k^T$ is $k \\times n$. Terms in this reduced space are represented by $U_k \\Sigma_k$ and documents by $\\Sigma_k V^T_k$. Reconstruct the matrix using the first $k=10$ singular values.\n",
      "\n",
      "3. Use agglomerative hierachical clustering with complete linkage to plot a dendrogram and comment on the likely number of  document clusters with $k = 100$. Use the dendrogram function from [SciPy ](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html).\n",
      "\n",
      "4. Determine how similar each of the original documents is to the new document `mystery.txt`. Since $A = U \\Sigma V^T$, we also have $V = A^T U S^{-1}$ using orthogonality and the rule for transposing matrix products. This suggests that in order to map the new document to the same concept space, first find the tf-idf vector $v$ for the new document - this must contain all (and only) the terms present in the existing tf-idx matrix. Then the query vector $q$ is given by $v^T U_k \\Sigma_k^{-1}$. Find the 10 documents most similar to the new document and the 10 most dissimilar. \n",
      "\n",
      "5. Many documents often have some boilerplate material such as organization information, Copyright, etc. at the front or back of the document. Does it matter that the front and back matter of each document is essentially identical for either LSA-based clustering (part 3) or information retrieval (part 4)? Why or why not?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. Load data, create tf-idf matrix"
     ]
    },
    {
<<<<<<< HEAD
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load data\n",
      "import cPickle\n",
      "docs = cPickle.load(open('pubmed.pic'))\n",
      "\n",
      "# Create tf-idf matrix\n",
      "m_tf_idf = tf_idf(docs)\n",
      "print \"The shape of the tf-idf matrix is: \", m_tf_idf.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The shape of the tf-idf matrix is:  (6488, 178)\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Perform SVD on the tf-idf matrix\n",
      "t, s, d = scipy.linalg.svd(m_tf_idf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print t.shape, s.shape, d.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6488, 6488) (178,) (178, 178)\n"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reconstruct the matrix using k = 10 singular values\n",
      "k = 10\n",
      "m_tf_idf10 = t[:, :k].dot(np.diag(s[:k])).dot(d[:k, :])\n",
      "print m_tf_idf10.shape\n",
      "print m_tf_idf10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6488, 178)\n",
        "[[ 0.126  0.015  0.110 ...,  0.113  0.003 -0.119]\n",
        " [ 0.022 -0.004  0.017 ..., -0.014 -0.016 -0.028]\n",
        " [ 0.093  0.033  0.266 ...,  0.073  0.122 -0.150]\n",
        " ..., \n",
        " [ 0.003 -0.002 -0.004 ...,  0.005  0.033 -0.017]\n",
        " [-0.004  0.049 -0.083 ...,  0.057  0.165 -0.124]\n",
        " [ 0.009 -0.025 -0.078 ..., -0.042 -0.026 -0.013]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 215
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Agglomerative hierarchical clustering and dendogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use agglomerative hierachical clustering with complete linkage to plot a dendrogram and \n",
      "# comment on the likely number of document clusters with k=100\n",
      "from scipy.spatial.distance import pdist\n",
      "from scipy.cluster.hierarchy import linkage, dendrogram\n",
      "k = 100\n",
      "m_tf_idf100 = t[:, :k].dot(np.diag(s[:k])).dot(d[:k, :])\n",
      "m_dist = pdist(m_tf_idf100.T, metric='cosine')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m_link = linkage(m_dist, method='complete')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree = dendrogram(m_link, orientation='right')\n",
      "print \"It looks like there are two big clusters, split at about 0.85. There is also a tiny outlier by itself, split very early at 1.0\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "It looks like there are two big clusters, split at about 0.85. There is also a tiny outlier by itself, split very early at 1.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEDCAYAAAAhsS8XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne2E/cOCSAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f307b036dd0>"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. Determine how similar each of the original documents is to the new document mystery.txt\n",
      "\n",
      "This suggests that in order to map the new document to the same concept space,\n",
      "First find the tf-idf vector for the new document - this must contain all (and only) the terms present in the existing tf-idx matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystery = open('mystery.txt', 'r').read()\n",
      "m_tf_idf_mystery = tf_idf({\"mystery\": mystery})\n",
      "print m_tf_idf_mystery.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(230, 1)\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then the query vector $q$ is given by $v^T U_k \\Sigma_k^{-1}$. Find the 10 documents most similar to the new document and the 10 most dissimilar."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use merge to create a tf_idf matrix for v that contains all of the existing terms. Note the fillna = 0\n",
      "m_merged = pd.merge(m_tf_idf, m_tf_idf_mystery, how='left', left_index=True, right_index=True).fillna(0)\n",
      "v = m_merged.iloc[:,-1]\n",
      "\n",
      "k = 100\n",
      "# Map the existing documents to the 100-singular-value concept space\n",
      "V_k = m_tf_idf100.T.dot(t[:, :k]).dot(np.linalg.inv(np.diag(s[:k])))\n",
      "# Map the mystery document to the 100-singular-value concept space\n",
      "q = v.T.dot(t[:, :k]).dot(np.linalg.inv(np.diag(s[:k])))[np.newaxis, :]\n",
      "\n",
      "# Construct the pairwise distance matrix between the mytery doc (q) and the existing docs (V_k), using functions created in question 1\n",
      "mystery_sim = broadcast_row(np.vstack((V_k, q)), distance_func=euclidean)[:-1,-1]\n",
      "\n",
      "# Get the indices of the 10 documents with largest distance (least similar)\n",
      "least_sim_idx = mystery_sim.argsort()[-10:][::-1]\n",
      "\n",
      "# Get the indices of the 10 documents with smallest distance (most similar)\n",
      "most_sim_idx = mystery_sim.argsort()[:10]"
=======
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load data\n",
      "import cPickle\n",
      "docs = cPickle.load(open('pubmed.pic'))\n",
      "\n",
      "# Create tf-idf matrix\n",
      "m_tf_idf = tf_idf(docs)\n",
      "print \"The shape of the tf-idf matrix is: \", m_tf_idf.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The shape of the tf-idf matrix is:  (6488, 178)\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Perform SVD on the tf-idf matrix\n",
      "t, s, d = np.linalg.svd(m_tf_idf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reconstruct the matrix using k = 10 singular values\n",
      "k = 10\n",
      "m_tf_idf10 = t[:, :k].dot(np.diag(s[:k])).dot(d[:k, :])"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 195
=======
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Agglomerative hierarchical clustering and dendogram"
     ]
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
<<<<<<< HEAD
      "# Most similar articles\n",
      "print \"\\n\".join(m_tf_idf.columns[most_sim_idx])"
=======
      "# Use agglomerative hierachical clustering with complete linkage to plot a dendrogram and \n",
      "# comment on the likely number of document clusters with k=100\n",
      "from scipy.cluster.hierarchy import linkage, dendrogram\n",
      "k = 100\n",
      "m_tf_idf100 = t[:, :k].dot(np.diag(s[:k])).dot(d[:k, :])\n",
      "R = dendrogram(linkage(m_tf_idf100, method='complete'))"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
<<<<<<< HEAD
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Artemisinin Resistance-Associated Polymorphisms at the K13-Propeller Locus are Absent in Plasmodium falciparum Isolates from Haiti.\n",
        "Prodrugs of reverse fosmidomycin analogs.\n",
        "Gestational Diabetes Mellitus Screening Using the One-Step Versus Two-Step Method in a High-Risk Practice.\n",
        "Minimal residual disease in myeloma by flow cytometry: independent prediction of survival benefit per log reduction.\n",
        "Myocarditis associated with Plasmodium vivax malaria: a case report.\n",
        "Autophagic flux determination in vivo and ex vivo.\n",
        "Babies Galore; or recent findings and future perspectives of pregnancy cohorts with a focus on immunity.\n",
        "Global malaria eradication and the importance of Plasmodium falciparum epidemiology in Africa.\n",
        "Correction: Angiopoietin-2 and Angiopoietin-2/Angiopoietin-1 Ratio as Indicators of Potential Severity of Plasmodium vivax Malaria in Patients with Thrombocytopenia.\n",
        "Disparities in Postpartum Follow-Up in Women With Gestational Diabetes Mellitus.\n"
       ]
      }
     ],
     "prompt_number": 204
=======
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEBCAYAAACaHMnBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7effbc1e76d0>"
       ]
      }
     ],
     "prompt_number": 43
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
<<<<<<< HEAD
      "# Least similar articles\n",
      "print \"\\n\".join(m_tf_idf.columns[least_sim_idx])"
=======
      "print m_tf_idf100.shape"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
<<<<<<< HEAD
        "Asian sand dust aggregate causes atopic dermatitis-like symptoms in Nc/Nga mice.\n",
        "Lineage-related cytotoxicity and clonogenic profile of 1,4-benzoquinone-exposed hematopoietic stem and progenitor cells.\n",
        "Simultaneous quantitation of chloroquine and primaquine by UPLC-DAD and comparison with a HPLC-DAD method.\n",
        "Increased sample volume and use of quantitative reverse-transcription PCR can improve prediction of liver-to-blood inoculum size in controlled human malaria infection studies.\n",
        "SMS photograph-based external quality assessment of reading and interpretation of malaria rapid diagnostic tests in the Democratic Republic of the Congo.\n",
        "Children's Learning and Goal-Setting at a Diabetes Camp.\n",
        "In Vitro Induction of Human Adipose-Derived Stem Cells into Lymphatic Endothelial-Like Cells.\n",
        "The effects of Ins2(Akita) diabetes and chronic angiotensin II infusion on cystometric properties in mice.\n",
        "Genome-wide association study of clinically defined gout identifies multiple risk loci and its association with clinical subtypes.\n",
        "Involvement of ROS-p38-H2AX axis in novel curcumin analogues-induced apoptosis in breast cancer cells.\n"
       ]
      }
     ],
     "prompt_number": 205
=======
        "(6488, 178)\n"
       ]
      }
     ],
     "prompt_number": 44
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
<<<<<<< HEAD
      "#### 5. Many documents often have some boilerplate material such as organization information, Copyright, etc. at the front or back of the document. Does it matter that the front and back matter of each document is essentially identical for either LSA-based clustering (part 3) or information retrieval (part 4)? Why or why not?\n",
      "\n",
      "It probably does not matter, because the tf-idf matrix takes into account how frequent a word happens across documents. If something occurs everywhere (Copy right, etc.) they are downweighted (by increasing $\\text{df}_i$ in $\\log \\frac{n}{1 + \\text{df}_i}$)"
=======
      "### 4. Determine how similar each of the original documents is to the new document mystery.txt"
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notes on the Pubmed articles\n",
      "----\n",
      "\n",
      "These were downloaded with the following script.\n",
      "\n",
      "```python\n",
      "from Bio import Entrez, Medline\n",
      "Entrez.email = \"YOUR EMAIL HERE\"\n",
      "import cPickle\n",
      "\n",
      "try:\n",
      "    docs = cPickle.load(open('pubmed.pic'))\n",
      "except Exception, e:\n",
      "    print e\n",
      "\n",
      "    docs = {}\n",
      "    for term in ['plasmodium', 'diabetes', 'asthma', 'cytometry']:\n",
      "        handle = Entrez.esearch(db=\"pubmed\", term=term, retmax=50)\n",
      "        result = Entrez.read(handle)\n",
      "        handle.close()\n",
      "        idlist = result[\"IdList\"]\n",
      "        handle2 = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
      "        result2 = Medline.parse(handle2)\n",
      "        for record in result2:\n",
      "            title = record.get(\"TI\", None)\n",
      "            abstract = record.get(\"AB\", None)\n",
      "            if title is None or abstract is None:\n",
      "                continue\n",
      "            docs[title] = '\\n'.join([title, abstract])\n",
      "            print title\n",
      "        handle2.close()\n",
      "    cPickle.dump(docs, open('pubmed.pic', 'w'))\n",
      "docs.values()\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
<<<<<<< HEAD
     "prompt_number": 48
=======
     "prompt_number": 43
>>>>>>> 27983cf412684dda0ce9d17c39096def1604af24
    }
   ],
   "metadata": {}
  }
 ]
}